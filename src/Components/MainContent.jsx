import React from "react";
import VideoEmbed from "../Components/VideoEmbed";

const content = {
  "Gemini Era": (
    <div id="Gemini-Era">
      <h2 className="text-3xl font-bold mb-4">The Gemini era</h2>
      <p className="mb-4">
        A year ago on the I/O stage we first shared our plans for Gemini: a
        frontier model built to be natively multimodal from the beginning, that
        could reason across text, images, video, code, and more. It marks a big
        step in turning any input into any output — an “I/O” for a new
        generation.
      </p>
      <p className="mb-4">
        Since then, we introduced the first Gemini models, our most capable yet.
        They demonstrated state-of-the-art performance on every multimodal
        benchmark. Two months later, we introduced Gemini 1.5 Pro, delivering a
        big breakthrough in long context. It can run 1 million tokens in
        production, consistently, more than any other large-scale foundation
        model yet.
      </p>
      <p className="mb-4">
        We want everyone to benefit from what Gemini can do. So we’ve worked
        quickly to share these advances with all of you. Today more than 1.5
        million developers use Gemini models across our tools. You’re using it
        to debug code, get new insights, and build the next generation of AI
        applications.
      </p>
      <p className="mb-4">
        We’ve also been bringing Gemini’s breakthrough capabilities across our
        products, in powerful ways. We’ll show examples today across Search,
        Photos, Workspace, Android and more.
      </p>
      <h2 className="text-3xl font-bold mb-4">Product progress</h2>
      <p className="mb-4">
        Today, all of our 2-billion user products use Gemini. And we’ve
        introduced new experiences too, including on mobile, where people can
        interact with Gemini directly through the app, now available on Android
        and iOS. And through Gemini Advanced which provides access to our most
        capable models. Over 1 million people have signed up to try it in just
        three months, and it continues to show strong momentum. Expanding AI
        Overviews in Search One of the most exciting transformations with Gemini
        has been in Google Search. In the past year, we’ve answered billions of
        queries as part of our Search Generative Experience. People are using it
        to Search in entirely new ways, and asking new types of questions,
        longer and more complex queries, even searching with photos, and getting
        back the best the web has to offer. We’ve been testing this experience
        outside of Labs. And we’re encouraged to see not only an increase in
        Search usage, but also an increase in user satisfaction.
      </p>
    </div>
  ),
  "Multimodality and long context": (
    <div id="Multimodality-and-long-context">
      <h2 className="text-3xl font-bold mb-4">
        Multimodality and long context
      </h2>
      <p className="mb-4">
        We’ve been rolling out Gemini 1.5 Pro with long context in preview over
        the last few months. We’ve made a series of quality improvements across
        translation, coding and reasoning. You’ll see these updates reflected in
        the model starting today. Now I’m excited to announce that we’re
        bringing this improved version of Gemini 1.5 Pro to all developers
        globally. In addition, today Gemini 1.5 Pro with 1 million context is
        now directly available for consumers in Gemini Advanced. This can be
        used across 35 languages.{" "}
      </p>
      <h2 className="text-3xl font-bold mb-4">Expanding the context window</h2>
      <p className="mb-4">
        One million tokens is opening up entirely new possibilities. It’s
        exciting, but I think we can push ourselves even further. So today,
        we’re expanding the context window to 2 million tokens, and making it
        available for developers in private preview. It's amazing to look back
        and see just how much progress we've made in a few months. And this
        represents the next step on our journey towards the ultimate goal of
        infinite context.
      </p>
      <VideoEmbed videoUrl="https://www.youtube.com/embed/My_13FXODdU" />
      <h2 className="text-3xl font-bold mb-4 mt-5">
        Bringing Gemini 1.5 Pro to Workspace
      </h2>
      <p className="mb-4">
        So far, we’ve talked about two technical advances: multimodality and
        long context. Each is powerful on its own. But together, they unlock
        deeper capabilities, and more intelligence. This comes to life with
        Google Workspace.
      </p>
      <p className="mb-4">
        People are always searching their emails in Gmail. We’re working to make
        it much more powerful with Gemini. So for example, as a parent, you want
        to stay informed about everything that’s going on with your child’s
        school. Gemini can help you keep up. Now we can ask Gemini to summarize
        all recent emails from the school. In the background, it’s identifying
        relevant emails, and even analyzing attachments, like PDFs. You get a
        summary of the key points and action items. Maybe you were traveling
        this week and couldn’t make the PTA meeting. The recording of the
        meeting is an hour long. If it’s from Google Meet, you can ask Gemini to
        give you the highlights. There’s a parents group looking for volunteers,
        and you’re free that day. So of course, Gemini can draft a reply.
      </p>
    </div>
  ),
  "AI agents": (
    <div id="AI-agents">
      <h2 className="text-3xl font-bold mb-4">AI agents</h2>
      <p className="mb-4">
        Taking this even further is one of the opportunities we see with AI
        Agents. I think about them as intelligent systems that show reasoning,
        planning, and memory. They are able to “think” multiple steps ahead, and
        work across software and systems, all to get something done on your
        behalf, and most importantly, under your supervision. We are still in
        the early days, but let me show you the kinds of use cases we’re working
        hard to solve. Let’s start with shopping. It’s pretty fun to shop for
        shoes, and a lot less fun to return them when they don’t fit. Imagine if
        Gemini could do all the steps for you: Searching your inbox for the
        receipt … Locating the order number from your email… Filling out a
        return form… Even scheduling a UPS pickup. That’s much easier, right?
        Let’s take another example that’s a bit more complex. Say you just moved
        to Chicago.
      </p>
      <p className="mb-4">
        You can imagine Gemini and Chrome working together to help you do a
        number of things to get ready — organizing, reasoning, synthesizing on
        your behalf. For example, you’ll want to explore the city and find
        services nearby — from dry cleaners to dog walkers. And you’ll have to
        update your new address across dozens of websites. Gemini can work
        across these tasks and will prompt you for more information when needed
        — so you are always in control. That part is really important — as we
        prototype these experiences we’re thinking hard about how to do it in a
        way that’s private, secure and works for everyone. These are simple use
        cases but they give you a good sense of the types of problems we want to
        solve, by building intelligent systems that think ahead, reason, and
        plan — all on your behalf. What it means for our mission The power of
        Gemini — with multimodality, long context and agents — brings us closer
        to our ultimate goal: making AI helpful for everyone. We see this as how
        we’ll make the most progress against our mission: Organizing the world’s
        information across every input, making it accessible via any output, and
        combining the world’s information, with the information in YOUR world,
        in a way that’s truly useful for you. Breaking new ground To realize the
        full potential of AI, we’ll need to break new ground. The Google
        DeepMind team has been hard at work on this.
      </p>
    </div>
  ),
  "Breaking new ground": (
    <div id="Breaking-new-ground">
      <h2 className="text-3xl font-bold mb-4">Breaking new ground</h2>
      <p className="mb-4">
        CBreaking new ground To realize the full potential of AI, we’ll need to
        break new ground. The Google DeepMind team has been hard at work on
        this. We’ve seen so much excitement around 1.5 Pro and its long context
        window. But we also heard from developers that they wanted something
        faster and more cost effective. So tomorrow, we’re introducing Gemini
        1.5 Flash, a lighter-weight model built for scale. It’s optimized for
        tasks where low latency and cost matter most. 1.5 Flash will be
        available in AI Studio and Vertex AI on Tuesday.
      </p>
      <p className="mb-4">
        Google was built for this. For 25 years, we’ve invested in world-class
        technical infrastructure. From the cutting-edge hardware that powers
        Search, to our custom tensor processing units that power our AI
        advances. Gemini was trained and served entirely on our fourth and fifth
        generation TPUs. And other leading AI companies, including Anthropic,
        have trained their models on TPUs as well. Today, we’re excited to
        announce our 6th generation of TPUs, called Trillium. Trillium is our
        most performant and most efficient TPU to date, delivering a 4.7x
        improvement in compute performance per chip over the previous
        generation, TPU v5e.
      </p>
    </div>
  ),
  Search: (
    <div id="Search">
      <h2 className="text-3xl font-bold mb-4">Search</h2>
      <p>Content for Search</p>
    </div>
  ),
  "More intelligent Gemini experiences": (
    <div id="More-intelligent-Gemini-experiences">
      <h2 className="text-3xl font-bold mb-4">
        More intelligent Gemini experiences
      </h2>
      <p>Content for More intelligent Gemini experiences</p>
    </div>
  ),
  "Responsible AI": (
    <div id="Responsible-AI">
      <h2 className="text-3xl font-bold mb-4">Responsible AI</h2>
      <p>Content for Responsible AI</p>
    </div>
  ),
  "Creating the future": (
    <div id="Creating-the-future">
      <h2 className="text-3xl font-bold mb-4">Creating the future</h2>
      <p>Content for Creating the future</p>
    </div>
  ),
};

const MainContent = ({ currentSection }) => {
  return (
    <div className="p-6 md:px-16 mx-2 mt-8">
      {Object.values(content).map((sectionContent, index) => (
        <div key={index} className="mb-16 text-lg">
          {sectionContent}
        </div>
      ))}
    </div>
  );
};

export default MainContent;
